# Reppy FastAPI - RAG Pipeline with LangChain

Production-ready RAG pipeline for Reppy AI fitness coaching using LangChain, AgentExecutor, and LCEL.

## Features

- ‚úÖ **Dual Execution Modes**
  - **Mode A**: Automatic routing to appropriate prompts based on input analysis
  - **Mode B**: Direct execution with specified prompt
  
- ‚úÖ **Dynamic Prompt System**
  - YAML-based prompts auto-discovered from `prompts/` directory
  - Three default prompts: `chat_response`, `generate_program`, `update_routine`
  - Extensible without code changes

- ‚úÖ **LangChain Integration**
  - Tool-calling agents with structured tools
  - LCEL pipelines with preprocessing, validation, and postprocessing
  - AgentExecutor with configurable iterations and timeouts

- ‚úÖ **RAG Components**
  - Qdrant vector database for exercise search and user memory
  - OpenAI embeddings for semantic search
  - MMR support for diversity (configurable)

- ‚úÖ **Domain Tools**
  - `calculate_one_rep_max`: Calculate 1RM from workout history
  - `get_exercise_details`: Fetch exercise information
  - `get_exercise_performance_records`: Get user's performance history
  - `recall_user_memory`: Search user's long-term memory
  - `find_relevant_exercises`: Semantic exercise search
  - `get_active_routines`: Fetch user's current workout routines

- ‚úÖ **Validation & Safety**
  - Pydantic v2 schemas for response validation
  - Domain guards for exercise and set type codes
  - Automatic retry on parsing errors

- ‚úÖ **Observability**
  - Loguru-based logging with rotation
  - Custom callback handlers for tool/LLM tracking
  - Optional LangSmith tracing integration

- ‚úÖ **Production-Ready**
  - FastAPI with async support
  - AWS Lambda consumer for SQS job processing
  - Health checks for all dependencies
  - Comprehensive test suite

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI   ‚îÇ  Mode A: POST /api/v1/route
‚îÇ   Routers   ‚îÇ  Mode B: POST /api/v1/run
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Action Router   ‚îÇ  Routes to: chat_response, generate_program, update_routine
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Prompt Loader    ‚îÇ  Loads YAML prompts dynamically
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Agent Builder   ‚îÇ  Creates LangChain tool-calling agent
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Agent Executor   ‚îÇ  Runs agent with tools
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LCEL Pipeline   ‚îÇ  Preprocess ‚Üí Execute ‚Üí Parse ‚Üí Validate ‚Üí Postprocess
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Validation     ‚îÇ  Schema validation + domain guards
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Project Structure

```
reppy-fastapi/
‚îú‚îÄ‚îÄ prompts/                  # YAML prompt files (auto-discovered)
‚îÇ   ‚îú‚îÄ‚îÄ chat_response.yaml
‚îÇ   ‚îú‚îÄ‚îÄ generate_program.yaml
‚îÇ   ‚îî‚îÄ‚îÄ update_routine.yaml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/              # Configuration singleton
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ baseconfig.py
‚îÇ   ‚îú‚îÄ‚îÄ infra/               # Infrastructure clients
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qdrant_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ express_client.py
‚îÇ   ‚îú‚îÄ‚îÄ common/              # Core RAG components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py       # Dynamic YAML loader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_retriever.py # Qdrant-backed retriever
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py         # LangChain tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py    # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observability.py # Logging & callbacks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lcel_pipeline.py # LCEL assembly
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_builder.py # Agent construction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py      # AgentExecutor wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action_router.py # Pattern-based routing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ action_router_llm.py # LLM-based routing
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routers.py
‚îÇ   ‚îú‚îÄ‚îÄ consumer/            # AWS Lambda handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lambda_handler.py
‚îÇ   ‚îî‚îÄ‚îÄ app.py               # FastAPI app
‚îú‚îÄ‚îÄ tests/                   # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_prompts.py
‚îÇ   ‚îú‚îÄ‚îÄ test_router.py
‚îÇ   ‚îú‚îÄ‚îÄ test_llm_router.py
‚îÇ   ‚îú‚îÄ‚îÄ test_qdrant_client.py
‚îÇ   ‚îú‚îÄ‚îÄ test_express_client.py
‚îÇ   ‚îú‚îÄ‚îÄ test_validation.py
‚îÇ   ‚îî‚îÄ‚îÄ test_retriever.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pytest.ini
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

## Prerequisites

- Python 3.11+
- OpenAI API key
- **Qdrant Cloud account** (or local Qdrant for development)
- Express API server

> üí° **Using Remote Qdrant**: This project is designed to work with Qdrant Cloud. See [QDRANT_SETUP.md](QDRANT_SETUP.md) for detailed setup instructions.

## Installation

1. **Clone the repository**

```bash
cd reppy-fastapi
```

2. **Create virtual environment**

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Configure environment**

```bash
cp env.example .env
# Edit .env with your configuration
```

**Required configuration:**
- `OPENAI_API_KEY`: Your OpenAI API key
- `QDRANT_URL`: Your Qdrant Cloud cluster URL (e.g., `https://xxxxx.cloud.qdrant.io`)
- `QDRANT_API_KEY`: Your Qdrant Cloud API key
- `EXPRESS_BASE_URL`: Express API server URL

**Example .env:**
```env
OPENAI_API_KEY=sk-your-openai-key
QDRANT_URL=https://your-cluster.cloud.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key
EXPRESS_BASE_URL=http://localhost:3000
```

> üìò See [QDRANT_SETUP.md](QDRANT_SETUP.md) for detailed Qdrant configuration

## Usage

### Running the FastAPI Server

```bash
python src/app.py
```

Or with uvicorn:

```bash
uvicorn src.app:app --reload --host 0.0.0.0 --port 8000
```

### API Endpoints

#### Mode A: Route and Execute (LLM-based)

```bash
curl -X POST http://localhost:8000/api/v1/route \
  -H "Content-Type: application/json" \
  -d '{
    "input": "I want to generate a new workout program",
    "user_id": "user-123",
    "context": {
      "conversation_history": [
        {"role": "user", "content": "Previous message..."}
      ]
    }
  }'
```

The router uses LLM-based intent classification for intelligent, context-aware routing. See [LLM_ROUTER_GUIDE.md](LLM_ROUTER_GUIDE.md) for details.

#### Mode B: Direct Execute

```bash
curl -X POST http://localhost:8000/api/v1/run \
  -H "Content-Type: application/json" \
  -d '{
    "prompt_key": "generate_program",
    "input": "Create a hypertrophy program",
    "user_id": "user-123",
    "context": {...}
  }'
```

#### List Available Prompts

```bash
curl http://localhost:8000/api/v1/prompts
```

#### Health Check

```bash
curl http://localhost:8000/api/v1/health
```

### Running Tests

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_router.py

# Run with coverage
pytest --cov=src tests/
```

### AWS Lambda Deployment

The Lambda handler is in `src/consumer/lambda_handler.py`.

**Sample SQS Message:**

```json
{
  "job_type": "generate_program",
  "payload": {
    "user_id": "user-123",
    "program_id": "prog-456",
    "context": {
      "user_profile": {...},
      "job_context": {...},
      "available_context": {...},
      "current_routines": [...]
    },
    "input": "Generate a new program"
  }
}
```

## Prompt System

### Adding New Prompts

1. Create a new YAML file in `prompts/` (e.g., `prompts/my_new_prompt.yaml`)
2. The prompt key is automatically the filename (without extension)
3. No code changes needed - the system auto-discovers new prompts

### Prompt YAML Structure

```yaml
version: 0.1.0
prompt_type: my_new_prompt

tools:
  - name: tool_name
    description: Tool description
    parameters:
      type: object
      properties:
        param1:
          type: string

variables:
  - name: variable_name
    description: Variable description
    schema:
      type: object
      properties: {...}

role: |
  You are an AI assistant...

instruction: |
  Follow these steps...

response_type: JSON
response_schema:
  type: object
  required: [field1]
  properties:
    field1:
      type: string
```

## Configuration

All configuration is in `src/config/baseconfig.py` and loaded from environment variables.

Key settings:
- **LLM**: Model, temperature, max tokens
- **Qdrant**: URL, API key, collections, search parameters
- **Express**: Base URL, auth, timeouts, retries
- **Agent**: Max iterations, parsing retries, timeouts
- **Observability**: Log level, LangSmith tracing

## Action Router Rules

The router evaluates inputs in order:

1. **Generate Program Rule**: Keywords like "generate program", "new block", "mesocycle", "create routine"
2. **Update Routine Rule**: Keywords like "update", "modify", "tweak", exercise-specific changes
3. **Scoring Fallback**: If multiple rules match, prefer tool-requiring prompts when input references data (1RM, percentages, performance records)
4. **Default**: Falls back to `chat_response`

## Validation

All LLM outputs are validated against Pydantic schemas:

- **chat_response**: `ChatResponse` schema
- **generate_program**: `GenerateProgramResponse` schema
- **update_routine**: `UpdateRoutineResponse` schema

Domain validators ensure:
- Exercise codes exist in `available_context`
- Set type codes are valid
- Required fields are present

## Observability

### Logging

Logs are written to:
- stdout (colored, formatted)
- `logs/reppy_YYYY-MM-DD.log` (rotated daily, 7-day retention)

### LangSmith Tracing

Enable in `.env`:
```
ENABLE_LANGSMITH=true
LANGSMITH_API_KEY=your-key
LANGSMITH_PROJECT=reppy-rag
```

### Callback Handler

Custom `ReppyCallbackHandler` tracks:
- Tool calls (name, input, output)
- LLM calls (prompts, generations)
- Errors and timing

## Development

### Adding New Tools

1. Define input schema in `src/common/tools.py`
2. Implement tool function (async)
3. Create `StructuredTool` in `ReppyTools` class
4. Add to `get_tools_for_prompt` method

### Adding New Validation Schemas

1. Create Pydantic model in `src/common/validation.py`
2. Add to `validate_response` function
3. Optionally add domain-specific validators

## License

MIT License

## Contributors

Built with ‚ù§Ô∏è by the Reppy team.

