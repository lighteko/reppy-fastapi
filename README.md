# Reppy FastAPI - RAG Pipeline with LangChain

Production-ready RAG pipeline for Reppy AI fitness coaching using LangChain, AgentExecutor, and LCEL.

## ğŸš€ Quick Start

```bash
# Install dependencies
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Configure environment
cp env.example .env
# Edit .env with your API keys

# Run the server
python src/app.py
```

**Test it:**
```bash
curl http://localhost:8000/api/v1/health
```

ğŸ“š **For detailed setup, examples, and development guide, see [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md)**

## âœ¨ Features

### Core Architecture
- **ğŸ”€ Dual Execution Modes**
  - **Mode A**: Automatic LLM-based routing to appropriate prompts
  - **Mode B**: Direct execution with specified prompt
  
- **ğŸ“ Dynamic Prompt System**
  - YAML-based prompts auto-discovered from `prompts/` directory
  - Three default prompts: `chat_response`, `generate_program`, `update_routine`
  - Extensible without code changes

- **ğŸ¤– LangChain Integration**
  - Tool-calling agents with structured tools
  - LCEL pipelines with preprocessing, validation, and postprocessing
  - AgentExecutor with configurable iterations and timeouts

- **ğŸ” RAG Components**
  - Qdrant vector database for exercise search and user memory
  - OpenAI embeddings for semantic search
  - MMR support for diversity (configurable)

### Domain Tools
- `calculate_one_rep_max`: Calculate 1RM from workout history
- `get_exercise_details`: Fetch exercise information
- `get_exercise_performance_records`: Get user's performance history
- `recall_user_memory`: Search user's long-term memory
- `find_relevant_exercises`: Semantic exercise search
- `get_active_routines`: Fetch user's current workout routines

### Production Ready
- âœ… FastAPI with async support
- âœ… Pydantic v2 schemas for validation
- âœ… AWS Lambda consumer for SQS job processing
- âœ… Health checks for all dependencies
- âœ… Loguru-based logging with rotation
- âœ… Optional LangSmith tracing
- âœ… Comprehensive test suite

## ğŸ—ï¸ Architecture

### Modular Structure

```
src/
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ agents/              # Agent building & execution
â”‚   â”œâ”€â”€ pipeline/            # LCEL pipeline & routing
â”‚   â”œâ”€â”€ tools/               # Tool implementations & RAG
â”‚   â””â”€â”€ utils/               # Prompts, validation, observability
â”œâ”€â”€ api/                     # FastAPI routers
â”œâ”€â”€ infra/                   # External clients (Qdrant, Express)
â”œâ”€â”€ config/                  # Configuration management
â””â”€â”€ consumer/                # AWS Lambda handler
```

### Request Flow

```
HTTP Request
    â†“
FastAPI Router
    â†“
[Mode A: Router] â†’ LLM Classification â†’ Prompt Selection
[Mode B: Direct] â†’ Specified Prompt
    â†“
LCEL Pipeline
    â”œâ”€â”€ Preprocess: Format context variables
    â”œâ”€â”€ Agent: LLM + Tools execution
    â”œâ”€â”€ Parse: Extract JSON from output
    â”œâ”€â”€ Validate: Schema + domain validation
    â””â”€â”€ Postprocess: Attach metadata
    â†“
JSON Response
```

## ğŸ”Œ API Endpoints

### Health Check
```bash
GET /api/v1/health
```

### Mode A: Route and Execute
```bash
POST /api/v1/route
Content-Type: application/json

{
  "input": "Generate a 3-day workout split for hypertrophy",
  "user_id": "user-123",
  "context": {
    "user_profile": {
      "goal": "HYPERTROPHY",
      "experience_level": "INTERMEDIATE"
    }
  }
}
```

### Mode B: Direct Execute
```bash
POST /api/v1/run
Content-Type: application/json

{
  "prompt_key": "chat_response",
  "input": "What's a good alternative to bench press?",
  "user_id": "user-123",
  "context": {
    "conversation_history": [
      {"role": "user", "content": "What's a good alternative to bench press?"}
    ]
  }
}
```

### List Available Prompts
```bash
GET /api/v1/prompts
```

## ğŸ“¦ Environment Variables

```bash
# Required
OPENAI_API_KEY=sk-...
QDRANT_URL=https://your-cluster.cloud.qdrant.io
QDRANT_API_KEY=your-api-key

# Optional
EXPRESS_BASE_URL=http://localhost:3000
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.7
AGENT_MAX_ITERATIONS=8
LOG_LEVEL=INFO
LANGSMITH_TRACING=false
```

See `env.example` for all configuration options.

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=src tests/

# Run examples
python examples/test_basic.py      # No external dependencies
python examples/usage_example.py   # Requires API keys
```

## ğŸ“š Documentation

- **[DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md)** - Development, examples, architecture deep dive
- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Production deployment guide

## ğŸ› ï¸ Technology Stack

- **Framework**: FastAPI 0.115+
- **AI**: LangChain 0.3+, OpenAI GPT-4o
- **Vector DB**: Qdrant
- **Validation**: Pydantic v2
- **Logging**: Loguru
- **Testing**: Pytest
- **Deployment**: Docker, AWS Lambda

## ğŸ“„ License

Proprietary - Reppy, Inc.

## ğŸ¤ Contributing

This is a private repository. For questions or issues, contact the development team.
